{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from keys import db_user, db_password, db_name, db_host, db_port\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select comment_body, 1 as \"is_bot\" from sus_user_comments where length(comment_body) > 15\n",
    "union\n",
    "select comment_body, 0 as \"is_bot\" from(\n",
    "\tselect * from norm_user_comments\n",
    "\twhere length(comment_body) > 10\n",
    "\torder by random()\n",
    "\tlimit 5311) as foo\n",
    "\"\"\"\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding \"gt\" to the stop words. this appears a lot with certain users bulleting their comment submissions\n",
    "custom_stop_words = [\"gt\", \"like\", \"com\", \"http\", \"https\", \"www\"]\n",
    "stop.update(custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=db_host, port=db_port, user=db_user, password=db_password, dbname=db_name)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(sql)\n",
    "query = cur.fetchall()\n",
    "comments = []\n",
    "bot_status = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(query)):\n",
    "    comments.append(query[i][0])\n",
    "    bot_status.append(query[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using full corpus\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('comment_features_weights.pkl', 'rb') as f:\n",
    "        feature_weight_list = pickle.load(f)\n",
    "    cv = CountVectorizer(stop_words=stop, max_df=0.5, min_df=1, lowercase=True, ngram_range=(1,1), strip_accents='ascii', vocabulary=feature_weight_list)\n",
    "    print(\"Using saved feature weights\")\n",
    "except:\n",
    "    cv = CountVectorizer(stop_words=stop, max_df=0.5, min_df=1, lowercase=True, ngram_range=(1,1), strip_accents='ascii', max_features=10000)\n",
    "    print(\"Using full corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_vector = cv.fit_transform(comments)\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "tfidf_vector = tfidf_transformer.transform(word_count_vector)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "df = pd.DataFrame(tfidf_vector.toarray(), columns=feature_names)\n",
    "df['is_bot'] = bot_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['is_bot'], axis=1)\n",
    "y = df['is_bot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def pipe_maker(classifier):\n",
    "    pipe = Pipeline([('clf', classifier)])\n",
    "    return pipe\n",
    "def gridsearch_maker(pipeline, params):\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='f1_weighted')\n",
    "    return grid\n",
    "def find_best_recall(gridsearch):\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    print('Best score:', gridsearch.best_score_)\n",
    "    print('Best parameters:', gridsearch.best_params_)\n",
    "    print('Best estimator:', gridsearch.best_estimator_)\n",
    "    return gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_etclf = pipe_maker(RandomForestClassifier())\n",
    "params_etclf = {'clf__n_estimators': [60, 80, 100, 120, 140, 160, 180, 200],\n",
    "                'clf__criterion': ['gini', 'entropy'],\n",
    "                'clf__max_features': ['auto'],\n",
    "                'clf__max_depth': [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_reg_params = find_best_recall(gridsearch_maker(pipe_etclf, params_etclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=180, criterion='entropy', max_features='auto', max_depth=None, n_jobs=-1)\n",
    "#build random forrest based off of best params\n",
    "# clf = best_reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.993\n",
      "Test set score: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69      1024\n",
      "           1       0.72      0.53      0.61      1089\n",
      "\n",
      "    accuracy                           0.65      2113\n",
      "   macro avg       0.67      0.66      0.65      2113\n",
      "weighted avg       0.67      0.65      0.65      2113\n",
      "\n",
      "[[802 222]\n",
      " [515 574]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print('Training set score: {:.3f}'.format(clf.score(X_train, y_train)))\n",
    "print('Test set score: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "(print(len(X.columns)))\n",
    "column_names = X.columns\n",
    "weights = clf.feature_importances_\n",
    "#make df of all features and their weights with weight larger than 0\n",
    "df_weights = pd.DataFrame(columns=['feature', 'weight'])\n",
    "for i in range(len(weights)):\n",
    "    if weights[i] > 0.00001:\n",
    "        df_weights = df_weights.append({'feature': column_names[i], 'weight': weights[i]}, ignore_index=True)\n",
    "df_weights = df_weights.sort_values(by='weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5731"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>crypto</td>\n",
       "      <td>0.006101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.005162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>tie</td>\n",
       "      <td>0.005117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>would</td>\n",
       "      <td>0.004805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>news</td>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>one</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>amp</td>\n",
       "      <td>0.004055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>trump</td>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>people</td>\n",
       "      <td>0.003966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>get</td>\n",
       "      <td>0.003817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>ties</td>\n",
       "      <td>0.003801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>think</td>\n",
       "      <td>0.003404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>cops</td>\n",
       "      <td>0.003262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.003217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>really</td>\n",
       "      <td>0.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>good</td>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>time</td>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>know</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>0.002862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>around</td>\n",
       "      <td>0.002794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>need</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>also</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>play</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>see</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>well</td>\n",
       "      <td>0.002512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature    weight\n",
       "1296   crypto  0.006101\n",
       "5104   thanks  0.005162\n",
       "5150      tie  0.005117\n",
       "5669    would  0.004805\n",
       "3404     news  0.004647\n",
       "3520      one  0.004436\n",
       "299       amp  0.004055\n",
       "5281    trump  0.004054\n",
       "3686   people  0.003966\n",
       "2158      get  0.003817\n",
       "5152     ties  0.003801\n",
       "5116    think  0.003404\n",
       "1203     cops  0.003262\n",
       "5102    thank  0.003217\n",
       "4123   really  0.003208\n",
       "2213     good  0.003052\n",
       "5158     time  0.003022\n",
       "2834     know  0.002899\n",
       "610   bitcoin  0.002862\n",
       "386    around  0.002794\n",
       "3378     need  0.002696\n",
       "277      also  0.002676\n",
       "3768     play  0.002646\n",
       "4509      see  0.002637\n",
       "5564     well  0.002512"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('comment_features_weights.pkl', 'wb') as f:\n",
    "#     pickle.dump(df_weights[\"feature\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clf to pickle file\n",
    "# with open('clf_v2.pkl', 'wb') as f:\n",
    "#     pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5306\n",
       "1    5259\n",
       "Name: is_bot, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bca96345a7f22c66cc2719fb9636a85b768ac8ff341f61afc63ea46e6bee51b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
