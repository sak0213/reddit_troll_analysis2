{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from keys import db_user, db_password, db_name, db_host, db_port\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select title as \"text\", 1 as \"is_bot\" from sus_user_posts\n",
    "union\n",
    "select title as \"text\", 0 as \"is_bot\" from (\n",
    "\tselect * from \n",
    "\tnorm_user_posts order by random() limit 9000) as foo\n",
    "\"\"\"\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=db_host, port=db_port, user=db_user, password=db_password, dbname=db_name)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(sql)\n",
    "query = cur.fetchall()\n",
    "posts = []\n",
    "bot_status = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(query)):\n",
    "    posts.append(query[i][0])\n",
    "    bot_status.append(query[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using saved feature weights\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('features_weights.pkl', 'rb') as f:\n",
    "        feature_weight_list = pickle.load(f)\n",
    "    cv = CountVectorizer(stop_words=stop, max_df=0.5, min_df=1, lowercase=True, ngram_range=(1,1), strip_accents='ascii', vocabulary=feature_weight_list)\n",
    "    print(\"Using saved feature weights\")\n",
    "except:\n",
    "    cv = CountVectorizer(stop_words=stop, max_df=0.5, min_df=1, lowercase=True, ngram_range=(1,1), strip_accents='ascii')\n",
    "    print(\"Using full corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(stop_words=stop, max_df=0.5, min_df=1, lowercase=True, ngram_range=(1,1), strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "word_count_vector = cv.fit_transform(posts)\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "tfidf_vector = tfidf_transformer.transform(word_count_vector)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "df = pd.DataFrame(tfidf_vector.toarray(), columns=feature_names)\n",
    "df['is_bot'] = bot_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['is_bot'], axis=1)\n",
    "y = df['is_bot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def pipe_maker(classifier):\n",
    "    pipe = Pipeline([('clf', classifier)])\n",
    "    return pipe\n",
    "def gridsearch_maker(pipeline, params):\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='f1_weighted')\n",
    "    return grid\n",
    "def find_best_recall(gridsearch):\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    print('Best score:', gridsearch.best_score_)\n",
    "    print('Best parameters:', gridsearch.best_params_)\n",
    "    print('Best estimator:', gridsearch.best_estimator_)\n",
    "    return gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_etclf = pipe_maker(RandomForestClassifier())\n",
    "params_etclf = {'clf__n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                'clf__criterion': ['gini', 'entropy'],\n",
    "                'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'clf__max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_best_recall(gridsearch_maker(pipe_etclf, params_etclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, criterion='entropy', max_features='log2', max_depth=None, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.991\n",
      "Test set score: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78      1743\n",
      "           1       0.81      0.70      0.75      1711\n",
      "\n",
      "    accuracy                           0.77      3454\n",
      "   macro avg       0.77      0.77      0.77      3454\n",
      "weighted avg       0.77      0.77      0.77      3454\n",
      "\n",
      "[[1454  289]\n",
      " [ 514 1197]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print('Training set score: {:.3f}'.format(clf.score(X_train, y_train)))\n",
    "print('Test set score: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9936\n"
     ]
    }
   ],
   "source": [
    "(print(len(X.columns)))\n",
    "column_names = X.columns\n",
    "weights = clf.feature_importances_\n",
    "#make df of all features and their weights with weight larger than 0\n",
    "df_weights = pd.DataFrame(columns=['feature', 'weight'])\n",
    "for i in range(len(weights)):\n",
    "    if weights[i] > 0.00001:\n",
    "        df_weights = df_weights.append({'feature': column_names[i], 'weight': weights[i]}, ignore_index=True)\n",
    "df_weights = df_weights.sort_values(by='weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7157"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police</td>\n",
       "      <td>0.009684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cops</td>\n",
       "      <td>0.007637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cop</td>\n",
       "      <td>0.007440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>0.006773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clinton</td>\n",
       "      <td>0.005389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trump</td>\n",
       "      <td>0.005232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>man</td>\n",
       "      <td>0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hillary</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>american</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>new</td>\n",
       "      <td>0.003441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>help</td>\n",
       "      <td>0.003233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>obama</td>\n",
       "      <td>0.003218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>us</td>\n",
       "      <td>0.003198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>amp</td>\n",
       "      <td>0.002825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature    weight\n",
       "0     police  0.009684\n",
       "1       cops  0.007637\n",
       "2        cop  0.007440\n",
       "3      black  0.006825\n",
       "4    america  0.006773\n",
       "6    clinton  0.005389\n",
       "5      trump  0.005232\n",
       "9        man  0.004115\n",
       "7    hillary  0.004111\n",
       "8   american  0.004022\n",
       "21       new  0.003441\n",
       "13      help  0.003233\n",
       "12     obama  0.003218\n",
       "14        us  0.003198\n",
       "15       amp  0.002825"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('features_weights_v2.pkl', 'wb') as f:\n",
    "#     pickle.dump(df_weights[\"feature\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clf to pickle file\n",
    "with open('clf_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bca96345a7f22c66cc2719fb9636a85b768ac8ff341f61afc63ea46e6bee51b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
